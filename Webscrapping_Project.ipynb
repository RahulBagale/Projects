{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Yt-MijfHbHCg"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scrapping Project start"
      ],
      "metadata": {
        "id": "TCUSmhgFCJVf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "website = 'https://subslikescript.com/movie/Titanic-120338'\n",
        "result = requests.get(website)\n",
        "content = result.text\n",
        "soup = BeautifulSoup(content, \"lxml\")\n",
        "box = soup.find('article', class_='main-article')\n",
        "title = box.find('h1').get_text()\n",
        "transcript = box.find('div', class_='full-script')\n",
        "transcript = transcript.get_text(strip=True, separator=' ')\n",
        "\n",
        "with open (f'{title}.txt','w') as file:\n",
        "  file.write(transcript)"
      ],
      "metadata": {
        "id": "Czaz8a29wuhy"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Getting links - trial"
      ],
      "metadata": {
        "id": "8LXHQB7dB6YP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "root = 'https://subslikescript.com'\n",
        "website = f'{root}/movies'\n",
        "r= requests.get(website)\n",
        "box = BeautifulSoup(r.text, 'lxml')\n",
        "links =[link['href'] for link in box.find_all('a', href = True)]\n",
        "print(links)\n",
        "\n"
      ],
      "metadata": {
        "id": "gh8rltVg4FD7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5004ce07-9f95-46c1-ccba-298f61a5b290"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/', '/movies', '/series', '/', '/movies_letter-sign', '/movies_letter-A', '/movies_letter-B', '/movies_letter-C', '/movies_letter-D', '/movies_letter-E', '/movies_letter-F', '/movies_letter-G', '/movies_letter-H', '/movies_letter-I', '/movies_letter-J', '/movies_letter-K', '/movies_letter-L', '/movies_letter-M', '/movies_letter-N', '/movies_letter-O', '/movies_letter-P', '/movies_letter-Q', '/movies_letter-R', '/movies_letter-S', '/movies_letter-T', '/movies_letter-U', '/movies_letter-V', '/movies_letter-W', '/movies_letter-X', '/movies_letter-Y', '/movies_letter-Z', 'http://subslikescript.com/movies?page=2', 'http://subslikescript.com/movies?page=3', 'http://subslikescript.com/movies?page=4', 'http://subslikescript.com/movies?page=5', 'http://subslikescript.com/movies?page=6', 'http://subslikescript.com/movies?page=7', 'http://subslikescript.com/movies?page=8', 'http://subslikescript.com/movies?page=9', 'http://subslikescript.com/movies?page=10', 'http://subslikescript.com/movies?page=1793', 'http://subslikescript.com/movies?page=1794', 'http://subslikescript.com/movies?page=2', 'movie/The_Breach-14229154', 'movie/Justice_League_Warworld-27687527', 'movie/Aval_Appadithaan-275205', 'movie/Kaazhcha-425162', 'movie/The_Inbetweeners-1716772', 'movie/Love_Object-328077', 'movie/May-December-January-22600514', 'movie/Kevin_Hart_Reality_Check-28227488', 'movie/Hama_no_asahi_no_usotsukidomo_to-16979594', 'movie/Arc-14663456', 'movie/Invisible_Waves-461970', 'movie/A_Night_to_Remember-241535', 'movie/JLA_Adventures_Trapped_in_Time-3468260', 'movie/Rollover-83006', 'movie/Douze_heures_dhorloge-52757', 'movie/Nipernaadi-239722', 'movie/Nadodikkattu-282778', 'movie/Pattanapravesam-292174', 'movie/Akka_Thangai-8908240', 'movie/Smokin_on_the_Moon-5872258', 'movie/The_Little_Vampire_3D-4729560', 'movie/National_Theatre_Live_Medea-4256612', 'movie/Blind-5316648', 'movie/Storytelling-250081', 'movie/Pookkal_Vidum_Thoodhu-8702688', 'movie/The_Play_of_God-199669', 'movie/Chemmeen-59028', 'movie/The_Scorpion_Monster-21808438', 'movie/Chakravyuham_The_Trap-27906902', 'movie/Bewafaa-363472', 'http://subslikescript.com/movies?page=2', 'http://subslikescript.com/movies?page=3', 'http://subslikescript.com/movies?page=4', 'http://subslikescript.com/movies?page=5', 'http://subslikescript.com/movies?page=6', 'http://subslikescript.com/movies?page=7', 'http://subslikescript.com/movies?page=8', 'http://subslikescript.com/movies?page=9', 'http://subslikescript.com/movies?page=10', 'http://subslikescript.com/movies?page=1793', 'http://subslikescript.com/movies?page=1794', 'http://subslikescript.com/movies?page=2', '/dmca']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Getting transcript - trial purpose"
      ],
      "metadata": {
        "id": "zeYpDqa0BguF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "    result = requests.get(f'{root}/movies?page={i}')\n",
        "    #print(result)\n",
        "    content = result.text\n",
        "    soup = BeautifulSoup(content, 'lxml')\n",
        "    box = soup.find('article', class_='main-article')\n",
        "    title = box.find('h1').get_text()\n",
        "    transcript = box.find('div', class_='full-script')\n",
        "    try:\n",
        "      transcript = transcript.get_text(strip=True, separator=' ')\n",
        "    except AttributeError:\n",
        "      print('There is no such attribute')\n",
        "    print('-'*20)\n",
        "    print(transcript)"
      ],
      "metadata": {
        "id": "E3NpGat64F4U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5a389e1-4a43-4aeb-b6b8-6394b8b43e01"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There is no such attribute\n",
            "--------------------\n",
            "None\n",
            "There is no such attribute\n",
            "--------------------\n",
            "None\n",
            "There is no such attribute\n",
            "--------------------\n",
            "None\n",
            "There is no such attribute\n",
            "--------------------\n",
            "None\n",
            "There is no such attribute\n",
            "--------------------\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Getting list of movie links of one page"
      ],
      "metadata": {
        "id": "VuNvpz61BMSo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://subslikescript.com/movies'\n",
        "r = requests.get(url)\n",
        "sp = BeautifulSoup(r.text, 'lxml')\n",
        "art = sp.find('article', class_ = 'main-article')\n",
        "script = art.find('ul', class_=\"scripts-list\")\n",
        "scr_list = script.find_all('a')\n",
        "page1_links = []\n",
        "for i in scr_list:\n",
        "  page1_links.append(i['href'])\n"
      ],
      "metadata": {
        "id": "ETc1UcF7-FgH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Getting transcript - trial purpose"
      ],
      "metadata": {
        "id": "ThVvRuTKAxJU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "root = 'https://subslikescript.com'\n",
        "#url = https://subslikescript.com/movie/The_Breach-14229154\n",
        "for i in page1_links[:2]:\n",
        "    result = requests.get(f'{root}/{i}')\n",
        "    #print(result)\n",
        "    content = result.text\n",
        "    soup = BeautifulSoup(content, 'lxml')\n",
        "    box = soup.find('article', class_='main-article')\n",
        "    title = box.find('h1').get_text()\n",
        "    transcript = box.find('div', class_='full-script')\n",
        "    try:\n",
        "      transcript = transcript.get_text(strip=True, separator=' ')\n",
        "    except AttributeError:\n",
        "      print('There is no such attribute')\n",
        "    with open(f'{title}.txt', 'w') as file:\n",
        "      file.write(transcript)\n",
        "    # print('-'*20)\n",
        "    # print(transcript)"
      ],
      "metadata": {
        "id": "g89SII7nhu5W"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Getting Page wise list of movie links - trial purpose"
      ],
      "metadata": {
        "id": "P_OmyQEuAdV3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "root = 'https://subslikescript.com'\n",
        "all_pages_links = []\n",
        "for i in range(2):\n",
        "    r = requests.get(f'{root}/movies?page={i}')\n",
        "    #url = 'https://subslikescript.com/movies'\n",
        "    #r = requests.get(url)\n",
        "    sp = BeautifulSoup(r.text, 'lxml')\n",
        "    art = sp.find('article', class_ = 'main-article')\n",
        "    script = art.find('ul', class_=\"scripts-list\")\n",
        "    scr_list = script.find_all('a')\n",
        "    page1_links = []\n",
        "    for i in scr_list:\n",
        "      page1_links.append(i['href'])\n",
        "    all_pages_links.append(page1_links)"
      ],
      "metadata": {
        "id": "JSA0-0HZpsm9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Getting nested list of movie links from all pages"
      ],
      "metadata": {
        "id": "_gjzZf1p62NP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "root = 'https://subslikescript.com'\n",
        "try:\n",
        "  all_pages_links = []\n",
        "  j=0\n",
        "  # total pages 1794 nos, we can etract data from all howeverd it is very memory consuming. Try to provide specific requirement.\n",
        "  while j<20:\n",
        "      r = requests.get(f'{root}/movies?page={j}')\n",
        "      #url = 'https://subslikescript.com/movies'\n",
        "      #r = requests.get(url)\n",
        "      sp = BeautifulSoup(r.text, 'lxml')\n",
        "      art = sp.find('article', class_ = 'main-article')\n",
        "      script = art.find('ul', class_=\"scripts-list\")\n",
        "      scr_list = script.find_all('a')\n",
        "      page1_links = []\n",
        "      for i in scr_list:\n",
        "        page1_links.append(i['href'])\n",
        "      all_pages_links.append(page1_links)\n",
        "      j+=1\n",
        "except AttributeError:\n",
        "  print('There is no such attribute')\n"
      ],
      "metadata": {
        "id": "_gFxCXu1tTmU"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_pages_links[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "JQfsizb71UJG",
        "outputId": "6937e89a-8c64-4742-fd60-5403d2c82f05"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'movie/The_Breach-14229154'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Getting all transcripts from nested list urls\n"
      ],
      "metadata": {
        "id": "N-F52UYZ3YRD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in all_pages_links[:1]:\n",
        "  for j in i:\n",
        "    result = requests.get(f'{root}/{j}')\n",
        "    #print(result)\n",
        "    content = result.text\n",
        "    soup = BeautifulSoup(content, 'lxml')\n",
        "    box = soup.find('article', class_='main-article')\n",
        "    title = box.find('h1').get_text()\n",
        "    transcript = box.find('div', class_='full-script')\n",
        "    try:\n",
        "      transcript = transcript.get_text(strip=True, separator=' ')\n",
        "    except AttributeError:\n",
        "      print('There is no such attribute')\n",
        "    with open(f'{title}.txt', 'w') as file:\n",
        "      file.write(transcript)\n",
        "    #print('-'*20)\n",
        "    #print(transcript)"
      ],
      "metadata": {
        "id": "ZGJ4OnOJtVUC"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1VWk8HUQu3cn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}